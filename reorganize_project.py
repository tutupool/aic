#!/usr/bin/env python3
"""
é¡¹ç›®ç»“æ„é‡ç»„è„šæœ¬
è‡ªåŠ¨å°†æ‚ä¹±çš„æ–‡ä»¶æŒ‰åŠŸèƒ½åˆ†ç±»åˆ°æ ‡å‡†ç›®å½•ç»“æ„ä¸­
"""

import os
import shutil
from pathlib import Path

def create_directories():
    """åˆ›å»ºæ‰€æœ‰éœ€è¦çš„ç›®å½•"""
    directories = [
        'src/data', 'src/models', 'src/training', 'src/inference', 'src/utils', 'src/config',
        'scripts',
        'data/raw', 'data/processed', 'data/external',
        'outputs/models', 'outputs/logs', 'outputs/predictions',
        'docs/competition',
        'backups'
    ]
    
    print("åˆ›å»ºç›®å½•ç»“æ„...")
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
        print(f"  âœ“ åˆ›å»º: {directory}")

def move_files():
    """ç§»åŠ¨æ–‡ä»¶åˆ°å¯¹åº”çš„ç›®å½•"""
    file_mapping = {
        # æ•°æ®æ–‡ä»¶
        'webfg400_train': 'data/raw/',
        'webinat5000_train.zip': 'data/external/',
        
        # æºä»£ç  - æ•°æ®å¤„ç†
        'data_loader.py': 'src/data/',
        'dataset_optimizer.py': 'src/data/',
        
        # æºä»£ç  - æ¨¡å‹
        'model.py': 'src/models/',
        
        # æºä»£ç  - è®­ç»ƒ
        'train.py': 'src/training/',
        'local_train.py': 'src/training/',
        'train_config_4060.py': 'src/training/',
        
        # æºä»£ç  - æ¨ç†
        'predict.py': 'src/inference/',
        'kaggle_predict.py': 'src/inference/',
        
        # æºä»£ç  - å·¥å…·
        'validate_code.py': 'src/utils/',
        'test_setup.py': 'src/utils/',
        
        # æºä»£ç  - é…ç½®
        'kernel-metadata.json': 'src/config/',
        
        # è„šæœ¬
        'setup_local_env.bat': 'scripts/',
        'kaggle_train.py': 'scripts/',
        
        # æ–‡æ¡£
        'README.md': 'docs/',
        'LOCAL_TRAINING_GUIDE.md': 'docs/',
        'PROJECT_REORGANIZATION_PLAN.md': 'docs/',
        'ã€2025ã€‘AICæŒ‘æˆ˜èµ›èµ›é¢˜è§„åˆ™_20250717145839_29-34(1).pdf': 'docs/competition/',
        
        # å¤‡ä»½æ–‡ä»¶
        'AIC1.zip': 'backups/',
        'webfg400_train.zip': 'backups/',
    }
    
    print("\nç§»åŠ¨æ–‡ä»¶...")
    moved_count = 0
    skipped_count = 0
    
    for source_file, target_dir in file_mapping.items():
        if os.path.exists(source_file):
            target_path = os.path.join(target_dir, source_file)
            
            # å¦‚æœæ˜¯ç›®å½•ï¼Œä½¿ç”¨shutil.move
            if os.path.isdir(source_file):
                shutil.move(source_file, target_dir)
                print(f"  âœ“ ç§»åŠ¨ç›®å½•: {source_file} -> {target_dir}")
            else:
                shutil.move(source_file, target_path)
                print(f"  âœ“ ç§»åŠ¨æ–‡ä»¶: {source_file} -> {target_path}")
            moved_count += 1
        else:
            print(f"  âš  è·³è¿‡: {source_file} (ä¸å­˜åœ¨)")
            skipped_count += 1
    
    print(f"\nç§»åŠ¨å®Œæˆ: {moved_count} ä¸ªæ–‡ä»¶å·²ç§»åŠ¨, {skipped_count} ä¸ªæ–‡ä»¶è·³è¿‡")

def update_file_references():
    """æ›´æ–°æ–‡ä»¶ä¸­çš„è·¯å¾„å¼•ç”¨"""
    print("\næ›´æ–°æ–‡ä»¶ä¸­çš„è·¯å¾„å¼•ç”¨...")
    
    # éœ€è¦æ›´æ–°çš„æ–‡ä»¶åŠå…¶è·¯å¾„æ˜ å°„
    update_files = {
        'src/training/local_train.py': {
            r"e:\\AIC1\\webfg400_train\\train": "data/raw/webfg400_train/train",
            r"\./output": "outputs/models"
        },
        'src/training/train.py': {
            r"e:\\AIC1\\webfg400_train\\train": "data/raw/webfg400_train/train",
            r"\./output": "outputs/models"
        },
        'src/inference/predict.py': {
            r"\./output": "outputs/models"
        },
        'scripts/setup_local_env.bat': {
            r"python local_train.py": "python ../src/training/local_train.py"
        }
    }
    
    updated_count = 0
    
    for file_path, replacements in update_files.items():
        if os.path.exists(file_path):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # æ‰§è¡Œæ›¿æ¢
                original_content = content
                for old_path, new_path in replacements.items():
                    content = content.replace(old_path, new_path)
                
                if content != original_content:
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(content)
                    print(f"  âœ“ æ›´æ–°: {file_path}")
                    updated_count += 1
                else:
                    print(f"  âš  æ— éœ€æ›´æ–°: {file_path}")
                    
            except Exception as e:
                print(f"  âŒ æ›´æ–°å¤±è´¥: {file_path} - {e}")
        else:
            print(f"  âš  æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    
    print(f"è·¯å¾„å¼•ç”¨æ›´æ–°å®Œæˆ: {updated_count} ä¸ªæ–‡ä»¶å·²æ›´æ–°")

def create_new_requirements():
    """åˆ›å»ºæ–°çš„requirements.txtåœ¨æ ¹ç›®å½•"""
    print("\nåˆ›å»ºæ–°çš„requirements.txt...")
    
    requirements_content = """torch>=2.0.0
 torchvision>=0.15.0
 torchaudio>=2.0.0
 matplotlib>=3.7.0
 tqdm>=4.65.0
 opencv-python>=4.8.0
 pandas>=2.0.0
 scikit-learn>=1.3.0
"""
    
    with open('requirements.txt', 'w', encoding='utf-8') as f:
        f.write(requirements_content)
    
    print("  âœ“ åˆ›å»º: requirements.txt")

def verify_structure():
    """éªŒè¯é‡ç»„åçš„ç»“æ„"""
    print("\n" + "="*60)
    print("éªŒè¯é¡¹ç›®ç»“æ„...")
    print("="*60)
    
    expected_files = [
        'requirements.txt',
        'src/data/data_loader.py',
        'src/models/model.py', 
        'src/training/local_train.py',
        'src/inference/predict.py',
        'scripts/setup_local_env.bat',
        'data/raw/webfg400_train',
        'docs/README.md'
    ]
    
    all_exists = True
    for file_path in expected_files:
        if os.path.exists(file_path):
            print(f"  âœ“ å­˜åœ¨: {file_path}")
        else:
            print(f"  âŒ ç¼ºå¤±: {file_path}")
            all_exists = False
    
    if all_exists:
        print("\nğŸ‰ é¡¹ç›®é‡ç»„æˆåŠŸï¼ç»“æ„éªŒè¯é€šè¿‡ï¼")
    else:
        print("\nâš ï¸  é¡¹ç›®é‡ç»„å®Œæˆï¼Œä½†æœ‰äº›æ–‡ä»¶ç¼ºå¤±")
    
    return all_exists

def main():
    """ä¸»å‡½æ•°"""
    print("="*60)
    print("ğŸ¤– WebFG-400 é¡¹ç›®ç»“æ„é‡ç»„å·¥å…·")
    print("="*60)
    
    # å¤‡ä»½è­¦å‘Š
    print("âš ï¸  è­¦å‘Š: æ­¤æ“ä½œå°†ç§»åŠ¨æ–‡ä»¶ï¼Œå»ºè®®å…ˆå¤‡ä»½é¡¹ç›®ï¼")
    response = input("æ˜¯å¦ç»§ç»­? (y/n): ")
    
    if response.lower() != 'y':
        print("æ“ä½œå–æ¶ˆ")
        return
    
    # æ‰§è¡Œé‡ç»„æ­¥éª¤
    create_directories()
    move_files()
    update_file_references()
    create_new_requirements()
    success = verify_structure()
    
    print("\n" + "="*60)
    if success:
        print("âœ… é¡¹ç›®é‡ç»„å®Œæˆï¼")
        print("\nä¸‹ä¸€æ­¥æ“ä½œ:")
        print("1. æµ‹è¯•è®­ç»ƒ: python src/training/local_train.py --help")
        print("2. æµ‹è¯•é¢„æµ‹: python src/inference/predict.py --help")
        print("3. é…ç½®ç¯å¢ƒ: scripts/setup_local_env.bat")
    else:
        print("âš ï¸  é‡ç»„å®Œæˆï¼Œä½†éœ€è¦æ‰‹åŠ¨æ£€æŸ¥ç¼ºå¤±æ–‡ä»¶")
    print("="*60)

if __name__ == "__main__":
    main()